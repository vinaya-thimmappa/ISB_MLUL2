{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBzFX6-IMDwe"
   },
   "source": [
    "# **Machine Learning - Unsupervised Learning - 1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Installing required packages\n",
    "\n",
    "You need following packages installed before you can do association rule mining\n",
    "\n",
    "* mlxtend\n",
    "* PyARMViz\n",
    "\n",
    "To install these packages, open Anaconda prompt and run the following commands\n",
    "\n",
    "* pip install mlxtend\n",
    "\n",
    "\n",
    "* pip install --index-url https://test.pypi.org/simple/ PyARMViz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h5>Currently only Testing </h5>\n",
    "<p> </p> \n",
    "<p>\n",
    "The PyARMViz package for visualizing rules has limited capabilities (there are some issues with orginal package, so we will install test package with limited features)\n",
    "</p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmneSK1I-Gct"
   },
   "source": [
    "## Session 1: Association Rule Discovery\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nk9B70YWpHVg"
   },
   "source": [
    "Let us load all the required packages"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T01:42:39.294857Z",
     "start_time": "2024-11-10T01:42:19.201133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install mlextend\n",
    "!pip install --index-url https://test.pypi.org/simple/ PyARMViz"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement mlextend (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for mlextend\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Looking in indexes: https://test.pypi.org/simple/\r\n",
      "Collecting PyARMViz\r\n",
      "  Obtaining dependency information for PyARMViz from https://test-files.pythonhosted.org/packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata\r\n",
      "\u001B[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)'))': /packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)'))': /packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)'))': /packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)'))': /packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)'))': /packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[31mERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='test-files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/ab/15/879fc7ca0904e5080c9ca7fdc239c5304c1ef03fe5c9809128ec9bf6177d/PyARMViz-0.1.3-py3-none-any.whl.metadata (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\r\n",
      "\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4OTNaJA-MKO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rsZ1cV2pF9I"
   },
   "source": [
    "Load the data and do some preprocessing\n",
    "\n",
    "**Note**: Some of the code and data are borrowed from *Data mining for Business Analytics* book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1KZoK8fpXwg"
   },
   "outputs": [],
   "source": [
    "fp_df = pd.read_csv(\"./data/Faceplate.csv\")\n",
    "fp_df.set_index('Transaction', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xnxnkovnpr24"
   },
   "outputs": [],
   "source": [
    "fp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wim6H9eqPmD"
   },
   "outputs": [],
   "source": [
    "fp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent items with Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-udPHXUpxyT"
   },
   "outputs": [],
   "source": [
    "frequent_items = apriori(fp_df, min_support=0.02, use_colnames=True)\n",
    "frequent_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can sort the frequent item sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_items.sort_values(['support'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_items_indexed = frequent_items.set_index('itemsets')\n",
    "frequent_items_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting frequent items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_items_indexed.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rules from frequent sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnvH8t0Nqh-w"
   },
   "source": [
    "You can select rules based on minimum **confidence**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em6mhvFrqTCx"
   },
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_items, metric=\"confidence\", min_threshold=0.4, num_itemsets = 5)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting support vs. confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.plot.scatter(x='support',y='confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h5>Better plots ahead </h5>\n",
    "<p> </p> \n",
    "<p>\n",
    "In the above plot we are using the native matplotlib to visualize, however, we have better PyARMViz package as we will see below for better visualization. \n",
    "</p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFfpqgicqngL"
   },
   "source": [
    "You can also select rules based on minimum **lift** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwzZK1X0qvva"
   },
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_items, metric=\"lift\", min_threshold=2, num_itemsets = 5)\n",
    "rules = rules.copy()\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oql2FBC6rPoz"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h5>Manipulations and filtering </h5>\n",
    "</div> \n",
    "\n",
    "**NOTE**: You can do any kind of manipulations and filtering based on \n",
    "\n",
    "* Based on lift, confidence, support thresholds\n",
    "* Antecedents\n",
    "* Any combination of these factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the rules\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h5>Package in testing mode </h5>\n",
    "</div> \n",
    "\n",
    "**NOTE**: As explained above, the PyARMViz package that we have installed and imported is currently only for testing, hence it might not be super polished. However, it helps us visualize the rules. You can install and experiment with the original package of PyARMViz in your projects if you plan to do one based on Association Rules. The package description is available [here](https://pypi.org/project/pyarmviz/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyARMViz import datasets\n",
    "from PyARMViz import PyARMViz\n",
    "from PyARMViz import Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert rules DataFrame to Rules list for PyARMViz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rules_df_viz_rules(rules_df, num_trans):\n",
    "    \"\"\"\n",
    "    Covert from the rules data frame from association rules to \n",
    "    rules list that can be visualized with PyARMViz package\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    rules_df: DataFrame\n",
    "        The rules dataframe from association_rules method\n",
    "    num_trans: int\n",
    "        Number of transactions used to build association rules\n",
    "    \"\"\"\n",
    "    rules_list = []\n",
    "    rule_dict = {'lhs':(), 'rhs':(), 'count_full':(), 'count_lhs':(), 'count_rhs':(), 'num_transactions':()}\n",
    "    for index, row in rules.iterrows():\n",
    "        antec = tuple(row['antecedents'])\n",
    "        conseq = list(row['consequents'])\n",
    "        count_full = row['support']*num_trans\n",
    "        count_lhs = row['antecedent support']*num_trans\n",
    "        count_rhs = row['consequent support']*num_trans\n",
    "        rule_dict['lhs']= antec\n",
    "        rule_dict['rhs']= conseq\n",
    "        rule_dict['count_full']= count_full\n",
    "        rule_dict['count_lhs']= count_lhs\n",
    "        rule_dict['count_rhs']= count_rhs\n",
    "        rule_dict['num_transactions'] = num_trans\n",
    "        rules_list.append(Rule.generate_rule_from_dict(rule_dict))\n",
    "\n",
    "    return rules_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of transactions from the original dataset\n",
    "num_trans = fp_df.shape[0] \n",
    "rules_list = convert_rules_df_viz_rules(rules, num_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = PyARMViz.generate_rule_strength_plot(rules_list, allow_compound_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = PyARMViz.generate_rule_start_end_plot(rules_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h5>Changing the strength plot</h5>\n",
    "</div> \n",
    "\n",
    "**NOTE**: \n",
    "\n",
    "* In the **strength plot** the size of the circle is based on the confidence. \n",
    "* I couldn't find an easy way to change that to support, lift or any easy way. However, I looked at the PyARMViz.py file to see how they generated this plot and change that to lift as did below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified based on PyARMViz.py file from the package\n",
    "from typing import List\n",
    "import plotly.graph_objects as go\n",
    "def generate_rule_start_end_plot_lift(rules:List, notebook_flag:bool = False, dot_size:int = 10):\n",
    "    unique_values = set()\n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    strength = []\n",
    "    for index, rule in enumerate(rules):\n",
    "        x_axis.append(str(rule.rhs))\n",
    "        y_axis.append(str(rule.lhs))\n",
    "        strength.append(dot_size*rule.lift)\n",
    "        unique_values.add(str(rule.rhs))\n",
    "        unique_values.add(str(rule.lhs))\n",
    "        \n",
    "    #Generate distance matrix view\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_axis,\n",
    "        y=y_axis,\n",
    "        mode=\"markers\",\n",
    "        marker = {'size':strength},\n",
    "        name='Association rules',\n",
    "    ))\n",
    "    \n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = generate_rule_start_end_plot_lift(rules_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing more complext rules from PyARMViz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_data = datasets.load_shopping_rules()\n",
    "rules_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = PyARMViz.generate_rule_strength_plot(rules_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = PyARMViz.generate_rule_start_end_plot(rules_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = generate_rule_start_end_plot_lift(rules_data, dot_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #1\n",
    "\n",
    "In the Faceplate dataset we have used, filter the rules based on the following criteria\n",
    "\n",
    "1. All rules with minimum confidence of 0.6\n",
    "2. All rules with minimum confidence of 0.4 and with 'Red' in the antecedent. \n",
    "3. All rules with minimum lift of 0.8 and with 'White' in the antecedent and 'Green' in consequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #2\n",
    "\n",
    "Load the CharlesBookClub.csv dataset, experiment on frequent items, association rules and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = pd.read_csv(\"./data/CharlesBookClub.csv\")\n",
    "book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['Seq#', 'ID#', 'Gender', 'M','R','F','FirstPurch','Related Purchase',\n",
    "         'Mcode','Rcode','Fcode','Yes_Florence','No_Florence']\n",
    "# Removing columns not used in the association rules\n",
    "count_books = book_df.drop(columns=ignore)\n",
    "count_books.head()\n",
    "\n",
    "#Converting the data to a binary incident matrix\n",
    "count_books[count_books>0] = 1\n",
    "count_books.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Z1mQ_tKP_1mu"
   ],
   "name": "MSBA_ML_Python.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
